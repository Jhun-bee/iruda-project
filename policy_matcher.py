# policy_matcher.py - ì˜ë¯¸ì  ê²€ìƒ‰ ì‹œìŠ¤í…œ
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import json
import os
import re
from datetime import datetime
import pandas as pd

class EnhancedPolicyMatcher:
    def __init__(self):
        print("ì •ì±… ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        try:
            self.model = SentenceTransformer('klue/roberta-large')
            print("KLUE RoBERTa ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"KLUE ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©: {e}")
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        # ì •ì±… ë°ì´í„° ë° ì„ë² ë”© ì´ˆê¸°í™”
        self.policies = []
        self.policy_embeddings = None
        self.policy_texts = []
        self.initialize_policy_embeddings()
        
        print(f"ì •ì±… ë§¤ì¹­ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ ({len(self.policies)}ê°œ ì •ì±…)")
    
    def initialize_policy_embeddings(self):
        """ì •ì±… ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì €ì¥"""
        try:
            # ì •ì±… ë°ì´í„° ë¡œë“œ
            self.policies = self.load_government_policies()
            
            if not self.policies:
                print("ê²½ê³ : ì •ì±… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ì •ì±…ë³„ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ìƒì„±
            self.policy_texts = []
            for policy in self.policies:
                combined_text = self.create_policy_search_text(policy)
                self.policy_texts.append(combined_text)
            
            # ì¼ê´„ ë²¡í„°í™” (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ)
            print("ì •ì±… ë°ì´í„° ë²¡í„°í™” ì¤‘...")
            self.policy_embeddings = self.model.encode(
                self.policy_texts, 
                show_progress_bar=True,
                batch_size=16,
                convert_to_numpy=True
            )
            
            print(f"ì •ì±… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {self.policy_embeddings.shape}")
            
        except Exception as e:
            print(f"ì •ì±… ì„ë² ë”© ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.policies = []
            self.policy_embeddings = None
    
    def create_policy_search_text(self, policy):
        """ì •ì±… ë°ì´í„°ë¥¼ ê²€ìƒ‰ì— ìµœì í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        text_parts = []
        
        # ì„œë¹„ìŠ¤ëª… (ê°€ì¤‘ì¹˜ ë†’ìŒ)
        if policy.get('ì„œë¹„ìŠ¤ëª…'):
            text_parts.append(f"ì„œë¹„ìŠ¤: {policy['ì„œë¹„ìŠ¤ëª…']}")
            text_parts.append(policy['ì„œë¹„ìŠ¤ëª…'])  # ì¤‘ë³µìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¦ê°€
        
        # ì§€ì›ëŒ€ìƒ (ì¤‘ìš”)
        if policy.get('ì§€ì›ëŒ€ìƒ'):
            text_parts.append(f"ëŒ€ìƒ: {policy['ì§€ì›ëŒ€ìƒ']}")
        
        # ì§€ì›ë‚´ìš© (í•µì‹¬)
        if policy.get('ì§€ì›ë‚´ìš©'):
            text_parts.append(f"ë‚´ìš©: {policy['ì§€ì›ë‚´ìš©']}")
        
        # ê¸°ê´€ëª…
        if policy.get('ê¸°ê´€ëª…'):
            text_parts.append(f"ê¸°ê´€: {policy['ê¸°ê´€ëª…']}")
        
        # ì‹ ì²­ë°©ë²•
        if policy.get('ì‹ ì²­ë°©ë²•'):
            text_parts.append(f"ì‹ ì²­: {policy['ì‹ ì²­ë°©ë²•']}")
        
        # êµ¬ë¶„ (ì¤‘ì•™ë¶€ì²˜, ì§€ìì²´, ë¯¼ê°„)
        if policy.get('êµ¬ë¶„'):
            text_parts.append(f"ë¶„ë¥˜: {policy['êµ¬ë¶„']}")
        
        return " ".join(text_parts)
    
    def semantic_search(self, query, user_profile=None, top_k=10):
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ì •ì±… ê²€ìƒ‰"""
        if self.policy_embeddings is None:
            print("ê²½ê³ : ì •ì±… ì„ë² ë”©ì´ ì—†ì–´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            return self.fallback_to_keyword_search(query)
        
        try:
            # 1ë‹¨ê³„: ì‚¬ìš©ì ì¿¼ë¦¬ ì „ì²˜ë¦¬ ë° í™•ì¥
            enhanced_query = self.enhance_search_query(query, user_profile)
            
            # 2ë‹¨ê³„: ì¿¼ë¦¬ ë²¡í„°í™”
            query_embedding = self.model.encode([enhanced_query])
            
            # 3ë‹¨ê³„: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(query_embedding, self.policy_embeddings)[0]
            
            # 4ë‹¨ê³„: ìƒìœ„ í›„ë³´ ì„ íƒ (ë” ë§ì´ ì„ íƒí•´ì„œ ê·œì¹™ ê¸°ë°˜ í•„í„°ë§)
            top_indices = np.argsort(similarities)[::-1][:top_k * 3]
            
            # 5ë‹¨ê³„: í›„ë³´ ì •ì±…ë“¤ì— ëŒ€í•´ ê·œì¹™ ê¸°ë°˜ ê²€ì¦ ë° ì ìˆ˜ ê³„ì‚°
            candidates = []
            for idx in top_indices:
                if similarities[idx] < 0.1:  # ë„ˆë¬´ ë‚®ì€ ìœ ì‚¬ë„ëŠ” ì œì™¸
                    continue
                    
                policy = self.policies[idx].copy()
                eligibility = self.check_eligibility(user_profile, policy) if user_profile else {'eligible': True, 'confidence': 0.5}
                
                # ì¢…í•© ì ìˆ˜ ê³„ì‚°
                combined_score = self.calculate_combined_score(
                    similarities[idx], 
                    eligibility,
                    query,
                    policy
                )
                
                candidates.append({
                    'policy': policy,
                    'semantic_score': float(similarities[idx]),
                    'eligibility': eligibility,
                    'combined_score': combined_score
                })
            
            # 6ë‹¨ê³„: ì¢…í•© ì ìˆ˜ë¡œ ì¬ì •ë ¬
            candidates.sort(key=lambda x: x['combined_score'], reverse=True)
            
            # 7ë‹¨ê³„: ìƒìœ„ ê²°ê³¼ë§Œ ë°˜í™˜ (ë§¤ì¹­ ì •ë³´ í¬í•¨)
            final_results = []
            for candidate in candidates[:top_k]:
                policy = candidate['policy']
                policy['_match_info'] = {
                    'semantic_score': round(candidate['semantic_score'], 3),
                    'eligibility_score': round(candidate['eligibility']['confidence'], 3),
                    'eligible': candidate['eligibility']['eligible'],
                    'combined_score': round(candidate['combined_score'], 3)
                }
                final_results.append(policy)
            
            return final_results
            
        except Exception as e:
            print(f"ì˜ë¯¸ì  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return self.fallback_to_keyword_search(query)
    
    def enhance_search_query(self, query, user_profile):
        """ì‚¬ìš©ì í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥"""
        enhanced_parts = [query]
        
        if user_profile:
            # ì§€ì› í•„ìš” ì˜ì—­ ì¶”ê°€
            if user_profile.get('support_needs'):
                enhanced_parts.extend(user_profile['support_needs'])
            
            # ì£¼ê±° ìƒí™© ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
            if user_profile.get('housing_status'):
                if 'ìë¦½ì¤€ë¹„ì²­ë…„' in user_profile['housing_status']:
                    enhanced_parts.append('ìë¦½ì¤€ë¹„ì²­ë…„ ì²­ì†Œë…„')
            
            # ë‚˜ì´ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
            age = user_profile.get('age')
            if age and 18 <= age <= 39:
                enhanced_parts.append('ì²­ë…„')
        
        return ' '.join(enhanced_parts)
    
    def calculate_combined_score(self, semantic_score, eligibility, query, policy):
        """ì˜ë¯¸ì  ìœ ì‚¬ë„, ìê²©ìš”ê±´, ì¶”ê°€ íœ´ë¦¬ìŠ¤í‹±ì„ ì¢…í•©í•œ ì ìˆ˜ ê³„ì‚°"""
        base_score = semantic_score * 0.6  # ì˜ë¯¸ì  ìœ ì‚¬ë„ 60%
        eligibility_score = eligibility['confidence'] * 0.3  # ìê²© ìš”ê±´ 30%
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤ 10%
        keyword_bonus = self.calculate_keyword_bonus(query, policy) * 0.1
        
        return base_score + eligibility_score + keyword_bonus
    
    def calculate_keyword_bonus(self, query, policy):
        """ì§ì ‘ì ì¸ í‚¤ì›Œë“œ ë§¤ì¹­ì— ëŒ€í•œ ë³´ë„ˆìŠ¤ ì ìˆ˜"""
        query_lower = query.lower()
        policy_text = (
            policy.get('ì„œë¹„ìŠ¤ëª…', '') + ' ' + 
            policy.get('ì§€ì›ë‚´ìš©', '') + ' ' +
            policy.get('ì§€ì›ëŒ€ìƒ', '')
        ).lower()
        
        bonus = 0
        query_words = query_lower.split()
        
        for word in query_words:
            if len(word) > 1 and word in policy_text:
                bonus += 0.2
        
        return min(bonus, 1.0)  # ìµœëŒ€ 1.0
    
    def check_eligibility(self, user_profile, policy):
        """ì‚¬ìš©ì í”„ë¡œí•„ê³¼ ì •ì±…ì˜ ìê²© ìš”ê±´ ë§¤ì¹­"""
        if not user_profile:
            return {'eligible': True, 'confidence': 0.5, 'reasons': ['í”„ë¡œí•„ ì •ë³´ ë¶€ì¡±']}
        
        checks = []
        total_weight = 0
        passed_weight = 0
        
        # ë‚˜ì´ ì¡°ê±´ í™•ì¸
        age_result = self.check_age_requirement(user_profile, policy)
        checks.append(('ë‚˜ì´', age_result))
        total_weight += 0.3
        if age_result['passed']:
            passed_weight += 0.3
        
        # ì†Œë“ ì¡°ê±´ í™•ì¸  
        income_result = self.check_income_requirement(user_profile, policy)
        checks.append(('ì†Œë“', income_result))
        total_weight += 0.4
        if income_result['passed']:
            passed_weight += 0.4
        
        # íŠ¹ë³„ ì¡°ê±´ í™•ì¸ (ìë¦½ì¤€ë¹„ì²­ë…„ ë“±)
        special_result = self.check_special_conditions(user_profile, policy)
        checks.append(('íŠ¹ë³„ì¡°ê±´', special_result))
        total_weight += 0.3
        if special_result['passed']:
            passed_weight += 0.3
        
        confidence = passed_weight / total_weight if total_weight > 0 else 0.5
        eligible = confidence >= 0.7  # 70% ì´ìƒ í†µê³¼í•´ì•¼ ìê²© ìˆìŒ
        
        return {
            'eligible': eligible,
            'confidence': confidence,
            'detailed_checks': checks,
            'reasons': [check[1]['reason'] for check in checks if not check[1]['passed']]
        }
    
    def check_age_requirement(self, user_profile, policy):
        """ë‚˜ì´ ì¡°ê±´ í™•ì¸"""
        user_age = user_profile.get('age')
        if not user_age:
            return {'passed': True, 'reason': 'ë‚˜ì´ ì •ë³´ ì—†ìŒ'}
        
        target_text = policy.get('ì§€ì›ëŒ€ìƒ', '') + policy.get('ì„œë¹„ìŠ¤ëª…', '')
        
        # ì²­ë…„ ëŒ€ìƒ í™•ì¸
        if 'ì²­ë…„' in target_text:
            if 18 <= user_age <= 39:
                return {'passed': True, 'reason': 'ì²­ë…„ ëŒ€ìƒ ì¡°ê±´ ì¶©ì¡±'}
            else:
                return {'passed': False, 'reason': f'ì²­ë…„ ëŒ€ìƒ ì¡°ê±´ ë¶ˆì¶©ì¡± (í˜„ì¬ {user_age}ì„¸)'}
        
        # êµ¬ì²´ì  ë‚˜ì´ ë²”ìœ„ í™•ì¸
        age_pattern = re.search(r'(\d+)ì„¸?\s*[~-ì´]\s*(\d+)ì„¸?', target_text)
        if age_pattern:
            min_age, max_age = map(int, age_pattern.groups())
            if min_age <= user_age <= max_age:
                return {'passed': True, 'reason': f'ë‚˜ì´ ì¡°ê±´ ì¶©ì¡± ({min_age}-{max_age}ì„¸)'}
            else:
                return {'passed': False, 'reason': f'ë‚˜ì´ ì¡°ê±´ ë¶ˆì¶©ì¡± ({min_age}-{max_age}ì„¸ í•„ìš”)'}
        
        return {'passed': True, 'reason': 'ë‚˜ì´ ì¡°ê±´ ëª…ì‹œë˜ì§€ ì•ŠìŒ'}
    
    def check_income_requirement(self, user_profile, policy):
        """ì†Œë“ ì¡°ê±´ í™•ì¸"""
        user_income = user_profile.get('income_level', '')
        if not user_income:
            return {'passed': True, 'reason': 'ì†Œë“ ì •ë³´ ì—†ìŒ'}
        
        target_text = policy.get('ì§€ì›ëŒ€ìƒ', '') + policy.get('ì§€ì›ë‚´ìš©', '')
        
        # ì†Œë“ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
        if any(word in target_text for word in ['ê¸°ì´ˆìƒí™œìˆ˜ê¸‰', 'ì°¨ìƒìœ„', 'ì €ì†Œë“']):
            if '50ë§Œì› ì´í•˜' in user_income or 'ì—†ìŒ' in user_income:
                return {'passed': True, 'reason': 'ì €ì†Œë“ì¸µ ëŒ€ìƒ ì¡°ê±´ ì¶©ì¡±'}
            else:
                return {'passed': False, 'reason': 'ì €ì†Œë“ì¸µ ëŒ€ìƒì´ë‚˜ ì†Œë“ ìˆ˜ì¤€ ë¶ˆì¶©ì¡±'}
        
        return {'passed': True, 'reason': 'íŠ¹ë³„í•œ ì†Œë“ ì¡°ê±´ ì—†ìŒ'}
    
    def check_special_conditions(self, user_profile, policy):
        """íŠ¹ë³„ ì¡°ê±´ í™•ì¸"""
        housing_status = user_profile.get('housing_status', '')
        support_needs = user_profile.get('support_needs', [])
        
        target_text = policy.get('ì§€ì›ëŒ€ìƒ', '') + policy.get('ì„œë¹„ìŠ¤ëª…', '')
        
        # ìë¦½ì¤€ë¹„ì²­ë…„ ì¡°ê±´
        if 'ìë¦½' in target_text and 'ìë¦½ì¤€ë¹„ì²­ë…„' in housing_status:
            return {'passed': True, 'reason': 'ìë¦½ì¤€ë¹„ì²­ë…„ ì¡°ê±´ ì¶©ì¡±'}
        
        # ì§€ì› ì˜ì—­ ë§¤ì¹­
        policy_lower = target_text.lower()
        need_match = False
        
        for need in support_needs:
            if (need == 'ì£¼ê±°ì§€ì›' and 'ì£¼ê±°' in policy_lower) or \
               (need == 'ì·¨ì—…ì§€ì›' and 'ì·¨ì—…' in policy_lower) or \
               (need == 'êµìœ¡ì§€ì›' and 'êµìœ¡' in policy_lower) or \
               (need == 'ê²½ì œì§€ì›' and ('ìƒê³„' in policy_lower or 'ê¸‰ì—¬' in policy_lower)):
                need_match = True
                break
        
        if need_match:
            return {'passed': True, 'reason': 'ì§€ì› í•„ìš” ì˜ì—­ ì¼ì¹˜'}
        
        return {'passed': True, 'reason': 'íŠ¹ë³„ ì¡°ê±´ ì—†ìŒ ë˜ëŠ” ë¶ˆëª…í™•'}
    
    def fallback_to_keyword_search(self, query):
        """ì˜ë¯¸ì  ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ fallback"""
        try:
            filtered_policies = []
            query_lower = query.lower()
            
            for policy in self.policies:
                policy_text = (
                    policy.get('ì„œë¹„ìŠ¤ëª…', '') + ' ' + 
                    policy.get('ê¸°ê´€ëª…', '') + ' ' +
                    policy.get('ì§€ì›ë‚´ìš©', '') + ' ' +
                    policy.get('ì§€ì›ëŒ€ìƒ', '')
                ).lower()
                
                if query_lower in policy_text:
                    filtered_policies.append(policy)
            
            return filtered_policies[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
            
        except Exception as e:
            print(f"Fallback ê²€ìƒ‰ë„ ì‹¤íŒ¨: {e}")
            return []
    
    def load_government_policies(self):
        """ì •ë¶€ ì •ì±… ë°ì´í„° ë¡œë“œ"""
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            excel_path = os.path.join(current_dir, 'ì •ë¶€ì •ì±…_ì„ì‹œDB.xlsx')
            
            if not os.path.exists(excel_path):
                print(f"ì •ì±… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")
                return []
            
            policies = []
            
            # Excel íŒŒì¼ì—ì„œ ì‹œíŠ¸ë³„ë¡œ ë°ì´í„° ì½ê¸°
            try:
                df_central = pd.read_excel(excel_path, sheet_name='ì¤‘ì•™ë¶€ì²˜')
                policies.extend(df_central.to_dict('records'))
                print(f"ì¤‘ì•™ë¶€ì²˜ ì •ì±… {len(df_central)}ê°œ ë¡œë“œ")
            except Exception as e:
                print(f"ì¤‘ì•™ë¶€ì²˜ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            try:
                df_local = pd.read_excel(excel_path, sheet_name='ì§€ìì²´')
                policies.extend(df_local.to_dict('records'))
                print(f"ì§€ìì²´ ì •ì±… {len(df_local)}ê°œ ë¡œë“œ")
            except Exception as e:
                print(f"ì§€ìì²´ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            try:
                df_private = pd.read_excel(excel_path, sheet_name='ë¯¼ê°„')
                policies.extend(df_private.to_dict('records'))
                print(f"ë¯¼ê°„ ì •ì±… {len(df_private)}ê°œ ë¡œë“œ")
            except Exception as e:
                print(f"ë¯¼ê°„ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # NaN ê°’ë“¤ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´
            for policy in policies:
                for key, value in policy.items():
                    if pd.isna(value):
                        policy[key] = ''
            
            print(f"ì´ {len(policies)}ê°œ ì •ì±… ë¡œë“œ ì™„ë£Œ")
            return policies
            
        except Exception as e:
            print(f"ì •ì±… ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_semantic_search():
    """ì˜ë¯¸ì  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    try:
        matcher = EnhancedPolicyMatcher()
        
        test_queries = [
            "ì£¼ê±° ì§€ì›ì´ í•„ìš”í•´ìš”",
            "ì·¨ì—… ë„ì›€ì„ ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤", 
            "ìƒí™œë¹„ ì§€ì› ì •ì±…",
            "ìë¦½ì¤€ë¹„ì²­ë…„ì„ ìœ„í•œ ë„ì›€"
        ]
        
        test_profile = {
            'age': 22,
            'housing_status': 'ìë¦½ì¤€ë¹„ì²­ë…„',
            'income_level': '50ë§Œì› ì´í•˜',
            'support_needs': ['ì£¼ê±°ì§€ì›', 'ê²½ì œì§€ì›']
        }
        
        for query in test_queries:
            print(f"\nğŸ” ê²€ìƒ‰ì–´: {query}")
            results = matcher.semantic_search(query, test_profile, top_k=3)
            
            for i, policy in enumerate(results, 1):
                print(f"{i}. {policy.get('ì„œë¹„ìŠ¤ëª…', 'N/A')}")
                if '_match_info' in policy:
                    match_info = policy['_match_info']
                    print(f"   ìœ ì‚¬ë„: {match_info['semantic_score']:.3f}")
                    print(f"   ìê²©ìš”ê±´: {'âœ…' if match_info['eligible'] else 'âŒ'}")
    
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_semantic_search()